{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulation de données \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "# Preprocessing des reviews \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "    # Pour filtrer la langue des avis\n",
    "from langdetect import detect, DetectorFactory \n",
    "from langdetect.lang_detect_exception import LangDetectException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHARGEMENT DES DONNEES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation d'un dataframe vide\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Boucle pour ouvrir et concaténer les 10 fichiers\n",
    "for i in range(1,11):\n",
    "    df_to_concat = pd.read_csv(f'Data/avis_ugc_part{i}.csv')\n",
    "    df = pd.concat([df, df_to_concat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>review</th>\n",
       "      <th>likes</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_nb_reviews</th>\n",
       "      <th>user_nb_photos</th>\n",
       "      <th>cinéma</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-11-10T07:41:44.880Z</td>\n",
       "      <td>Il n’a pas admissible qu’une grosse chaîne de ...</td>\n",
       "      <td>0</td>\n",
       "      <td>anne degroux</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>UGC Ciné Cité Les Halles</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2024-11-09T10:32:32.722Z</td>\n",
       "      <td>Pratique, plein de salles et bonne programmati...</td>\n",
       "      <td>0</td>\n",
       "      <td>Géraldine Sauvenay</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>UGC Ciné Cité Les Halles</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2024-11-09T08:45:17.039Z</td>\n",
       "      <td>Nettoyez vos écrans, ça commence à se voir !</td>\n",
       "      <td>0</td>\n",
       "      <td>M G</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>UGC Ciné Cité Les Halles</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-11-08T20:13:38.816Z</td>\n",
       "      <td>The theater still has a bed bug problem. Sat d...</td>\n",
       "      <td>0</td>\n",
       "      <td>Cordelia Ryan</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>UGC Ciné Cité Les Halles</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-11-08T15:32:14.074Z</td>\n",
       "      <td>VOLUME beaucoup trop fort mon dieu!! On était ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Spei</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>UGC Ciné Cité Les Halles</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                      date  \\\n",
       "0       1  2024-11-10T07:41:44.880Z   \n",
       "1       4  2024-11-09T10:32:32.722Z   \n",
       "2       3  2024-11-09T08:45:17.039Z   \n",
       "3       1  2024-11-08T20:13:38.816Z   \n",
       "4       1  2024-11-08T15:32:14.074Z   \n",
       "\n",
       "                                              review  likes  \\\n",
       "0  Il n’a pas admissible qu’une grosse chaîne de ...      0   \n",
       "1  Pratique, plein de salles et bonne programmati...      0   \n",
       "2       Nettoyez vos écrans, ça commence à se voir !      0   \n",
       "3  The theater still has a bed bug problem. Sat d...      0   \n",
       "4  VOLUME beaucoup trop fort mon dieu!! On était ...      0   \n",
       "\n",
       "            user_name  user_nb_reviews  user_nb_photos  \\\n",
       "0        anne degroux                2               0   \n",
       "1  Géraldine Sauvenay                3               0   \n",
       "2                 M G                2               0   \n",
       "3       Cordelia Ryan                2               1   \n",
       "4                Spei               83               0   \n",
       "\n",
       "                     cinéma language  \n",
       "0  UGC Ciné Cité Les Halles       fr  \n",
       "1  UGC Ciné Cité Les Halles       fr  \n",
       "2  UGC Ciné Cité Les Halles       fr  \n",
       "3  UGC Ciné Cité Les Halles       fr  \n",
       "4  UGC Ciné Cité Les Halles       fr  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant de passer nos données dans les modèles, nous devons les mettre en forme. Tout d’abord, j’ai constaté que la colonne `language` contient souvent des informations incorrectes sur la langue. Pour remédier à cela, nous allons utiliser la librairie `langdetect`, qui s’appuie sur la détection de langue de Google pour identifier la langue correcte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"df_clean = df.copy()\"\"\"\n",
    "\n",
    "# Importation du fichier déjà nettoyé car le code est long à tourner\n",
    "df_clean = pd.read_csv('Data/avis_ugc_fr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"DetectorFactory.seed = 24\n",
    "\n",
    "# Fonction pour détecter la langue d'un texte donné\n",
    "def detect_language(text: str) -> str | None:\n",
    "    try:\n",
    "        # Tente de détecter la langue du texte\n",
    "        return detect(text)\n",
    "    except LangDetectException:\n",
    "        # En cas d'erreur (par exemple, si le texte est vide ou ambigu), retourne None\n",
    "        return None\n",
    "\n",
    "# Applique la fonction de détection de langue à chaque avis dans la colonne 'review'\n",
    "df_clean['language_detected'] = df_clean['review'].map(detect_language)\n",
    "\n",
    "# Filtre les données pour ne conserver que les avis détectés en français ('fr')\n",
    "df_clean = df[df['language_detected'] == 'fr']\n",
    "\n",
    "# Exporte le DataFrame filtré dans un fichier CSV\n",
    "df_clean.to_csv('Data/avis_ugc_fr.csv', index=False)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" Nombre d'avis non francais supprimés : {df.shape[0] - df_clean.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des stop words français de la librairie NLTK\n",
    "stop_words = set(stopwords.words('french'))\n",
    "\n",
    "# Ajout de stop words détectés dans les avis \n",
    "custom_stop_words = {\",\", \".\", \"a\", \"c'est\", \"!\", \"film\", \"cinéma\", \n",
    "                     \"si\", \"plus\", \"ugc\", \"ca\", \"là\", \"où\", \"deux\", \n",
    "                     \"ça\", \"h\", \"qu\", \"il\", \"''\", '``', \"-\", \"(\", \")\",\n",
    "                     \"..\", \"€\", \"?\", \"....\", \"//\", \":\", \"/\", \";\", '’'\n",
    "                    }\n",
    "stop_words.update(custom_stop_words)\n",
    "\n",
    "# Initialisation d'un lemmatiseur pour réduire les mots à leur forme de base\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_reviews(reviews: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Cette fonction prend une série pandas contenant des avis textuels et applique un prétraitement\n",
    "    pour chaque avis. Elle effectue les étapes suivantes :\n",
    "    \n",
    "    1. Convertit chaque avis en minuscules pour uniformiser le texte.\n",
    "    2. Supprime les chiffres et remplace les apostrophes par des espaces pour éviter les séparations incorrectes.\n",
    "    3. Tokenise chaque avis, c'est-à-dire qu'elle divise le texte en mots individuels.\n",
    "    4. Supprime les stop words (mots courants sans importance) à partir d'une liste de stop words standard en français,\n",
    "       enrichie de mots spécifiques au contexte.\n",
    "    5. Applique la lemmatisation, qui réduit les mots à leur forme de base (par exemple, \"films\" devient \"film\").\n",
    "    \n",
    "    Paramètres :\n",
    "    reviews (pd.Series) : Série pandas contenant les avis textuels.\n",
    "    \n",
    "    Retourne :\n",
    "    pd.Series : Série pandas contenant des listes de mots prétraités pour chaque avis.\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Convertir en minuscules et supprimer les chiffres et les apostrophes\n",
    "    reviews = reviews.str.lower().str.replace(r'\\d+', '', regex=True).str.replace(\"'\", ' ')\n",
    "\n",
    "    # Appliquer tokenisation, suppression des stop words, et lemmatisation\n",
    "    reviews = reviews.apply(lambda review: [lemmatizer.lemmatize(word) \n",
    "                                            for word in word_tokenize(review) \n",
    "                                            if word not in stop_words\n",
    "                                           ])\n",
    "\n",
    "\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = preprocess_reviews(df_clean['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_word_cloud(reviews: pd.Series, title: str = None, subplot: tuple[int] = None, background_image_path: str = None) -> None:\n",
    "    \"\"\"\n",
    "    Génère et affiche un nuage de mots basé sur le contenu textuel d'une série pandas contenant des avis.\n",
    "    La fonction peut également afficher le nuage de mots sur une image de fond spécifiée.\n",
    "    \n",
    "    Paramètres :\n",
    "    - reviews (pd.Series) : Série pandas contenant les avis textuels. Tous les avis sont concaténés pour créer le nuage de mots.\n",
    "    - title (str, optionnel) : Titre à afficher au-dessus du nuage de mots. Si None, aucun titre n'est affiché.\n",
    "    - subplot (tuple[int], optionnel) : Spécifie l'emplacement du nuage de mots dans une grille de sous-plots sous la forme (nrows, ncols, index).\n",
    "      Utilisé lorsque le nuage de mots doit être affiché dans une figure avec plusieurs sous-graphiques.\n",
    "    - background_image_path (str, optionnel) : Chemin d'accès à une image de fond pour le nuage de mots.\n",
    "      Si fourni, le nuage de mots prendra la forme de cette image. Si None, le fond sera blanc par défaut.\n",
    "    \n",
    "    Retourne :\n",
    "    - None : La fonction affiche directement le nuage de mots en utilisant `matplotlib.pyplot` et ne retourne rien.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Concatène tous les avis en une seule chaîne de texte\n",
    "    text = ' '.join(reviews.astype(str))\n",
    "    \n",
    "    # Charge l'image de fond si spécifiée, sinon crée un nuage de mots avec un fond blanc\n",
    "    if background_image_path is not None:\n",
    "        background_image = np.array(Image.open(background_image_path))\n",
    "        wordcloud = WordCloud(width=800, height=400, background_color='white', mask=background_image, contour_width=1, contour_color='black').generate(text)\n",
    "    else:\n",
    "        wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
    "    \n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    # Positionne le nuage de mots dans un sous-plot si `subplot` est spécifié\n",
    "    if subplot is not None :\n",
    "        plt.subplot(subplot[0], subplot[1], subplot[2])\n",
    "    \n",
    "    # Affiche le nuage de mots et enlève les axes\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Ajoute un titre si spécifié\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_word_cloud(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boucle pour afficher un word cloud pour chaque note\n",
    "for i in np.sort(df_clean['rating'].unique()):\n",
    "    reviews_per_note =  preprocess_reviews(df_clean[df_clean['rating'] == i]['review'])\n",
    "    \n",
    "    title = f' Word Cloud des avis {i} étoiles'\n",
    "    my_word_cloud(reviews_per_note, title, subplot=(3,2,i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Le mot \"salle(s)\" apparaît aussi bien dans les avis positifs que négatifs, ce qui suggère qu'il n'est pas un indicateur fiable de sentiment. Il serait donc pertinent de le retirer, au moins pour la création du nuage de mots, afin d'obtenir une visualisation plus représentative des termes associés aux avis positifs ou négatifs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_clean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Boucle pour afficher un word cloud pour chaque note\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39msort(\u001b[43mdf_clean\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()):\n\u001b[0;32m      3\u001b[0m     reviews_per_note \u001b[38;5;241m=\u001b[39m  preprocess_reviews(df_clean[df_clean[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      5\u001b[0m     reviews_per_note \u001b[38;5;241m=\u001b[39m reviews_per_note\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m words: [word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msalle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msalles\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_clean' is not defined"
     ]
    }
   ],
   "source": [
    "# Boucle pour afficher un word cloud pour chaque note\n",
    "for i in np.sort(df_clean['rating'].unique()):\n",
    "    reviews_per_note =  preprocess_reviews(df_clean[df_clean['rating'] == i]['review'])\n",
    "    \n",
    "    reviews_per_note = reviews_per_note.apply(lambda words: [word for word in words if word not in ['salle', 'salles']])\n",
    "    \n",
    "    title = f' Word Cloud des avis {i} étoiles'\n",
    "    my_word_cloud(reviews_per_note, title, subplot=(3,2,i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Word Cloud des avis 1 étoile :**\n",
    "\n",
    "    * Les mots les plus fréquents incluent \"place\", \"séance\", et \"bien\". Cela pourrait suggérer des commentaires sur l'emplacement, l'organisation des séances, ou même des aspects de confort. Cependant, dans un contexte de note basse, ces termes sont probablement utilisés de manière négative (ex. : mauvaise organisation des séances, inconfort des places).\n",
    "    * Les termes \"dommage\", \"problème\", et \"mal\" apparaissent également, ce qui renforce l'idée de critiques.\n",
    "\n",
    "2. **Word Cloud des avis 2 étoiles :**\n",
    "\n",
    "    * On retrouve des mots similaires comme \"place\" et \"tout\". \"Dommage\" est également présent, ce qui indique des critiques mitigées.\n",
    "    * Le mot \"bien\" reste fréquent, mais dans ce contexte, il pourrait être utilisé pour souligner des aspects corrects dans un avis globalement négatif.\n",
    "\n",
    "3. **Word Cloud des avis 3 étoiles :**\n",
    "\n",
    "    * Les termes \"bien\" et \"peu\" sont dominants, suggérant des avis modérés où des aspects positifs sont soulignés, mais avec des réserves (ex. : \"peu d'espace\", \"bien mais pourrait être mieux\").\n",
    "    * D’autres mots comme \"dommage\", \"prix\", et \"petite\" indiquent probablement des points d'amélioration signalés par les utilisateurs.\n",
    "\n",
    "4. **Word Cloud des avis 4 étoiles :**\n",
    "\n",
    "    * Le mot \"bien\" devient encore plus dominant, accompagné de \"très\", \"bon\", et \"propre\". Cela suggère des avis majoritairement positifs, où la qualité et le confort sont reconnus.\n",
    "    * Des termes comme \"agréable\" et \"choix\" apparaissent, ce qui peut indiquer une satisfaction avec les options disponibles et l’atmosphère générale.\n",
    "\n",
    "5. **Word Cloud des avis 5 étoiles :**\n",
    "\n",
    "    * Les mots les plus fréquents sont \"très\", \"super\", \"bien\", et \"agréable\", soulignant une satisfaction élevée.\n",
    "    * On voit aussi \"parfait\", \"personnel\", et \"choix\", ce qui indique une expérience globalement positive avec de nombreux aspects appréciés, y compris le service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ugc_project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
